= UFRN - Processamento Digital de Imagens (DCA0445)
Leonardo Carvalho Amaral
:toc: left
:toc-title: Sumário
:doctype: book

== Prefácio
Esta página foi feita para expor os resultados encontrados nas atividades de Processamento Digital de Imagens do professor Agostinho Brito Júnior, realizadas pelo aluno Leonardo Carvalho Amaral.

== 1. Exercício 1

[.text-justify]
O primeiro exercício consta em executar o código <<hello>>, a fim de mostrar a imagem escolhida através do opencv, utilizando arquivo <<Makefile>>.
[[Makefile, Makefile]]
[source,Makefile]
.Makefile
----
.SUFFIXEX:
.SUFFIXES: .CPP

GCC = g++

.cpp:
        &(GCC) -Wall -Wunused -std=c++11 -O2 $< -o $@ 'pkg-config --cflags --libs opencv4'
----
[[hello, hello.cpp]]
[source,cpp]
.hello.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
  cv::Mat image;
  image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
  cv::imshow("image", image);
  cv::waitKey();
  return 0;
}
----

[#biel]
.Biel
image::./Images/Exercicio_1/biel.png[align="center"]

== Exercício 2
[.text-justify]
O Exercício 2 pedia que se realizasse dois códigos, um de negativar uma certa região especificada pelo usuário de uma imagem, chamado de <<regions>> e outro que invertesse os quadrantes da imagem, chamado de <<troca>>.

[[regions,regions.cpp]]
[source,cpp]
.regions.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
  cv::Mat image;
  cv::Vec3b val;

  image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
  if(!image.data)
    std::cout << "nao abriu imagem" << std::endl;

  cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);

  int x1, y1, x2, y2;

  std::cout << "Coordenadas x1, x2, y1 e y2: " << std::endl;
  std::cin >> x1 >> x2 >> y1 >> y2;

  for(int i = x1; i <= x2; i++){
    for(int j = y1; j <= y2; j++){
      image.at<uchar>(i,j)=255 - image.at<uchar>(i,j);
    }
  }

  cv::imshow("janela", image);
  imwrite("regions.png",image);  
  cv::waitKey();
  return 0;
}
----
[#bielregion]
.Saída do programa regions.cpp
image::./Images/Exercicio_2/regions.png[align="center"]

[[troca,trocaregioes.cpp]]
[source,cpp]
.trocaregioes.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
  cv::Mat image;
  cv::Vec3b val;

  image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
  if(!image.data)
    std::cout << "nao abriu imagem" << std::endl;

  cv::namedWindow("original", cv::WINDOW_AUTOSIZE);
  cv::namedWindow("trocada", cv::WINDOW_AUTOSIZE);

  int rows = image.rows;
  int cols = image.cols;

  cv::imshow("original", image);  

  cv::Mat image2(rows, cols, CV_8U);

  for(int i = 0; i < rows; i++){
    for(int j = 0; j < cols; j++){
      if(i < rows/2 && j <= cols/2){
        image2.at<uchar>(i,j)=image.at<uchar>((rows/2) + i,(cols/2) + j);
      }
      if(i > rows/2 && j <= cols/2){
        image2.at<uchar>(i,j)=image.at<uchar>(i - (rows/2),(cols/2) + j);
      }
      if(i < rows/2 && j > cols/2){
        image2.at<uchar>(i,j)=image.at<uchar>((rows/2) + i,j - (cols/2));
      }
      if(i > rows/2 && j > cols/2){
        image2.at<uchar>(i,j)=image.at<uchar>(i - (rows/2),j - (cols/2));
      }
    }
  }

  cv::imshow("trocada", image2);
  imwrite("troca.png", image2);  
  cv::waitKey();

  return 0;
}
----
[#bieltroca]
.Saída do programa trocaregioes.cpp
image::./Images/Exercicio_2/troca.png[align="center"]

== Exercício 3
[.text-justify]
Nesta atividade, o objetivo era criar o programa <<storage>> que gerasse uma imagem de uma senoíde de 4 períodos e a gravando em formato PNG E YML, a fim de analisar os diferentes métodos de armazenamento, já que PNG armazena os dados em unsigned char e YML em float.

[[storage, imagestorage.cpp]]
[source, cpp]
.imagestorage.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <sstream>
#include <string>
#include <fstream>

int SIDE = 256;
int PERIODOS = 4;

int main(int argc, char** argv) {
  std::stringstream ss_img, ss_yml;
  cv::Mat image;

  ss_yml << "senoide-" << SIDE << ".yml";
  image = cv::Mat::zeros(SIDE, SIDE, CV_32FC1);

  cv::FileStorage fs(ss_yml.str(), cv::FileStorage::WRITE);

  for (int i = 0; i < SIDE; i++) {
    for (int j = 0; j < SIDE; j++) {
      image.at<float>(i, j) = 63 * sin(2 * M_PI * PERIODOS * j / SIDE) + 64;
    }
  }

  fs << "mat" << image;
  fs.release();
  
  float diff[SIDE];
////////ofstream ymp//////////////////////////
  std::ofstream outfile("sen-ymp.txt");
  for(int i = 0; i < SIDE; i++){
    outfile << i << " " << image.at<float>(SIDE/2, i) << std::endl;
    diff[i] = image.at<float>(SIDE/2, i);
  }
  
  outfile.close();
////////////////////////////////////////////////
  image.convertTo(image, CV_8U);
////////////ofstream png//////////////////////////////
  std::ofstream outfile2("sen-png.txt");
  for(int i = 0; i < SIDE; i++){
    outfile2 << i << " " << int(image.at<uchar>(SIDE/2, i)) << std::endl;
    diff[i] = diff[i] - int(image.at<uchar>(SIDE/2, i));
  }
  
  outfile2.close();
//////////////////////////

  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  
  ss_img << "senoide-" << SIDE << ".png";
  cv::imwrite(ss_img.str(), image);


  fs.open(ss_yml.str(), cv::FileStorage::READ);
  fs["mat"] >> image;

  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);

  cv::imshow("image", image);
  cv::waitKey();

////////////ofstream difference//////////////////////////////
  std::ofstream outfile3("sen-difference.txt");
  for(int i = 0; i < SIDE; i++){
    outfile3 << i << " " << abs(diff[i]) << std::endl;
  }
  
  outfile3.close();
//////////////////////////

  return 0;
}
----
[#storageimg]
.Saída do programa imagestorage.cpp
image::./Images/Exercicio_3/senoide-256.png[align="center"]

[.text-justify]
Também seria necessário extrair os valores de uma linha dos dois arquivos gerados e comparar a diferença de valores entre eles.

[#dif]
.Gráfico de diferenças
image::./Images/Exercicio_3/diff-plot.png[align="center"]
[.text-justify]
Como é possível notar, a diferença entre eles é apenas de casas decimais e não afetam na representação da imagem.


== Exercício 4
[.text-justify]
O exercício 4 tem como objetivo a criação de um programa capaz de decodificar uma imagem que passou por um processo de esteganografia, o processo de esconder uma imagem dentro de outra imagem. Para isto, bastava realizar o processo reverso do programa <<esteg-encode.cpp>> fornecido na questão.

[source,cpp]
.esteganografia.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char ** argv){
    cv::Mat codifiedImage, hiddenImage;
    cv::Vec3b codifiedVal, hiddenVal;
    int bitn = 3;
    std::string archivename;

    std::cout << "Digite o nome da imagem codificada: ";
    std::cin >> archivename;

    codifiedImage = cv::imread(archivename, cv::IMREAD_COLOR);
    if(codifiedImage.empty()){
        std::cout << "Imagem nao carregou corretamente" << std::endl;
        return (-1);
    }

    hiddenImage = codifiedImage.clone();

    for(int i = 0; i < codifiedImage.rows; i++){
        for(int j = 0; j < codifiedImage.cols; j++){
            
            codifiedVal = codifiedImage.at<cv::Vec3b>(i,j);
            
            codifiedVal[0] = codifiedVal[0] << (8-bitn);
            codifiedVal[1] = codifiedVal[1] << (8-bitn);
            codifiedVal[2] = codifiedVal[2] << (8-bitn);

            hiddenImage.at<cv::Vec3b>(i,j) = codifiedVal;
        }
    }

    cv::imshow("hiddenimage", hiddenImage);
    cv::waitKey();
    cv::imwrite("hiddenimage.png", hiddenImage);

    return 0;
}
----

[#codificada]
.Imagem codificada
image::./Images/Exercicio_4/front.png[align="center"]

[#escondidad]
.Saída do programa: Imagem escondida
image::./Images/Exercicio_4/hiddenimage.png[align="center"]

== Exercício 5
[.text-justify]
O exercício 5 definia que a partir do processo de floodfill e labeling, o programa <<improved>> deveria ser capaz de encontrar bolhas em uma imagem, conta-lás e definir se a bolha tinha um buraco ou não. Para isto, bolhas nas bordas deveriam ser eliminadas pois não se podia afirmar que estas estavam fechadas.

[[improved, improvedlabeling.cpp]]
[source,cpp]
.improvedlabeling.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;

int main(int argc, char** argv) {
  cv::Mat image;
  int width, height;
  int nobjects, nbubbles, nopen;
  bool open;

  cv::Point p;
  image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);

  if (!image.data) {
    std::cout << "imagem nao carregou corretamente\n";
    return (-1);
  }

  width = image.cols;
  height = image.rows;
  std::cout << width << "x" << height << std::endl;

  p.x = 0;
  p.y = 0;

  ////////////Border Objects Remover//////////////
  for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
      if (image.at<uchar>(i, j) == 255 && (i == 0 || j == 0 || i == height-1 || j == width-1)){
        p.x = j;
        p.y = i;
        cv::floodFill(image, p, 0);
      }
    }
  }

  p.x = 0;
  p.y = 0;
  cv::floodFill(image, p, 127);

  // busca objetos presentes
  nobjects = 0;
  nbubbles = 0;
  nopen = 0;
  for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
      if (image.at<uchar>(i, j) == 255) {
        nobjects++;
        // x e y são trocadas.
        p.x = j;
        p.y = i;
        cv::floodFill(image, p, 254);
        open = false;
        for (int i = p.y; i < height; i++) {
            for (int j = p.x; j < width; j++) {
                if(image.at<uchar>(i, j) == 0 && image.at<uchar>(i, j-1) < 254){
                    nopen++;
                    p.x = j;
                    p.y = i;
                    cv::floodFill(image, p, 1);
                    open = true;
                }
                if(open) break;
            }
            if(open) break;
        }
        if(open == false) nbubbles++;
      }
    }
  }
  std::cout << "a figura tem " << nobjects << " bolhas" << std::endl;
  std::cout << "com " << nopen << " bolhas com buracos" << std::endl;
  std::cout << "e " << nbubbles << " bolhas sem buracos" << std::endl;
  cv::imshow("image", image);
  cv::imwrite("improvedlabelling.png", image);
  cv::waitKey();
  return 0;
}
----

[#bolhas]
.Imagem com bolhas
image::./Images/Exercicio_5/bolhas.png[align="center"]

[#label]
.Saída do programa improvedlabeling.cpp
image::./Images/Exercicio_5/improvedlabelling.png[align="center"]

== Exercício 6
[.text-justify]
Esta atividade buscava, através da manipulação do histograma de uma imagem, realçar imagem escuras através da equalização do histograma e ser capaz de detectar mudanças em video, a fim criar um sensor de movimento.

[source,cpp]
.equalize.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
  cv::Mat image, imageGray, equalized;
  int width, height;
  cv::VideoCapture cap;
  int key;

	cap.open(0);
  
  if(!cap.isOpened()){
    std::cout << "cameras indisponiveis";
    return -1;
  }
  
  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);  
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout << "largura = " << width << std::endl;
  std::cout << "altura  = " << height << std::endl;

  while(1){
    cap >> image;
    cv::cvtColor(image, imageGray, cv::COLOR_BGR2GRAY);
    cv::equalizeHist(imageGray, equalized);

    cv::imshow("image", equalized);
    key = cv::waitKey(30);
    if(key == 27) break;
  }
  return 0;
}
----
[#eq]
.Saída do programa equalize.cpp
image::./Images/Exercicio_6/equal.png[align="center"]
[.text-justify]
Através da equalização do histograma, a imagem de baixa luminosidade teve seu brilho realçado.

[source,cpp]
.motionsensor.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <algorithm>

int main(int argc, char** argv){
  cv::Mat image;
  int width, height;
  cv::VideoCapture cap;
  std::vector<cv::Mat> planes;
  cv::Mat histB, histB2;
  int control, counter;
  float diff;
  bool enabler;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key;

	cap.open(0);
  
  if(!cap.isOpened()){
    std::cout << "cameras indisponiveis";
    return -1;
  }
  
  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);  
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout << "largura = " << width << std::endl;
  std::cout << "altura  = " << height << std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat histImgB(histh, histw, CV_8UC3, cv::Scalar(0,0,0));

  enabler = false;

  while(1){
    cap >> image;
    cv::split (image, planes);
    cv::calcHist(&planes[0], 1, 0, cv::Mat(), histB, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    
    counter = 0;
    control = 0;

    if(enabler == true){
        for(int i = 0; i < nbins; i++){
            float max = std::max(histB.at<float>(i), histB2.at<float>(i));
            float min = std::min(histB.at<float>(i), histB2.at<float>(i));
            diff = min/max;
            if(abs(diff) <= 0.9) counter++;
        }
    }

    if(counter >= nbins/2) control = 1;

    histB2 = histB.clone();
    
    for(int i=0; i<nbins; i++){
      cv::line(histImgB,
               cv::Point(i, histh),
               cv::Point(i, 0),
               cv::Scalar(255*control, 255*control, 255*control), 1, 8, 0);
    }
    histImgB.copyTo(image(cv::Rect(0, 0 ,nbins, histh)));
    cv::imshow("image", image);
    enabler = true;
    key = cv::waitKey(30);
    if(key == 27) break; 
  }

  return 0;
}
----
[#nomotion]
.Saída do programa motiondetector.cpp quando não há movimento
image::./Images/Exercicio_6/nomotion.png[align="center"]

[#motion]
.Saída do programa motiondetector.cpp quando há movimento
image::./Images/Exercicio_6/motion.png[align="center"]
[.text-justify]
Este programa compara os histogramas dos frames de um vídeo e indica se houve mudanças significativas em seus níveis, mostrando que houve mudança na cena. O retângulo branco na parte superior esquerda da imagem fica branco quando o programa percebe o movimento e vira preto quando a imagem fica estática.

== Exercício 7
[.text-justify]
No exercício 7, pediasse que fosse aplicado um filtro espacial laplaciano do gaussiano e para isto, o programa <<lap>> aplicava o filtro gaussiano e logo após aplicava o filtro laplaciano na imagem que tinha sido filtrada

[[lap,laplgauss.cpp]]
[source,cpp]
.laplgauss.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

void printmask(cv::Mat &m) {
  for (int i = 0; i < m.size().height; i++) {
    for (int j = 0; j < m.size().width; j++) {
      std::cout << m.at<float>(i, j) << ",";
    }
    std::cout << "\n";
  }
}

int main(int, char **) {
  cv::VideoCapture cap;  // open the default camera
  float media[] = {0.1111, 0.1111, 0.1111, 0.1111, 0.1111,
                   0.1111, 0.1111, 0.1111, 0.1111};
  float gauss[] = {0.0625, 0.125,  0.0625, 0.125, 0.25,
                   0.125,  0.0625, 0.125,  0.0625};
  float horizontal[] = {-1, 0, 1, -2, 0, 2, -1, 0, 1};
  float vertical[] = {-1, -2, -1, 0, 0, 0, 1, 2, 1};
  float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
  float boost[] = {0, -1, 0, -1, 5.2, -1, 0, -1, 0};
  bool log = false;

  cv::Mat frame, framegray, frame32f, frameFiltered;
  cv::Mat mask(3, 3, CV_32F);
  cv::Mat mask2(3, 3, CV_32F);
  cv::Mat result;
  double width, height;
  int absolut;
  char key;

  cap.open(0);

  if (!cap.isOpened())  // check if we succeeded
    return -1;

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);
  std::cout << "largura=" << width << "\n";
  ;
  std::cout << "altura =" << height << "\n";
  ;
  std::cout << "fps    =" << cap.get(cv::CAP_PROP_FPS) << "\n";
  std::cout << "format =" << cap.get(cv::CAP_PROP_FORMAT) << "\n";

  cv::namedWindow("filtroespacial", cv::WINDOW_NORMAL);
  cv::namedWindow("original", cv::WINDOW_NORMAL);

  mask = cv::Mat(3, 3, CV_32F, media);

  absolut = 1;  // calcs abs of the image

  for (;;) {
    cap >> frame;  // get a new frame from camera
    cv::cvtColor(frame, framegray, cv::COLOR_BGR2GRAY);
    cv::flip(framegray, framegray, 1);
    cv::imshow("original", framegray);
    framegray.convertTo(frame32f, CV_32F);
    cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask,
                 cv::Point(1, 1), 0);
    if(log == true){
        mask2 = cv::Mat(3, 3, CV_32F, laplacian);
        cv::filter2D(frameFiltered, frameFiltered, frame32f.depth(), mask2,
                 cv::Point(1, 1), 0);
    }
    
    if (absolut) {
      frameFiltered = cv::abs(frameFiltered);
    }

    frameFiltered.convertTo(result, CV_8U);

    cv::imshow("filtroespacial", result);
    
    key = (char)cv::waitKey(10);
    if (key == 27) break;  // esc pressed!
    switch (key) {
      case 'a':
        absolut = !absolut;
        break;
      case 'm':
        mask = cv::Mat(3, 3, CV_32F, media);
        printmask(mask);
        log = false;
        break;
      case 'g':
        mask = cv::Mat(3, 3, CV_32F, gauss);
        printmask(mask);
        log = false;
        break;
      case 'h':
        mask = cv::Mat(3, 3, CV_32F, horizontal);
        printmask(mask);
        log = false;
        break;
      case 'v':
        mask = cv::Mat(3, 3, CV_32F, vertical);
        printmask(mask);
        log = false;
        break;
      case 'l':
        mask = cv::Mat(3, 3, CV_32F, laplacian);
        printmask(mask);
        log = false;
        break;
      case 'b':
        mask = cv::Mat(3, 3, CV_32F, boost);
        log = false;
        break;
      case 'o':
        mask = cv::Mat(3, 3, CV_32F, gauss);
        log = true;
        break;
      case 'c':
        cv::imwrite("captura.png", result);
        break;
      default:
        break;
    }
  }
  return 0;
}
----
[#laplaciano]
.Saída do programa laplgauss.cpp apenas com a filtragem laplaciana
image::./Images/Exercicio_7/laplaciano_a.png[align="center"]

[laplg]
.Saída do programa laplgauss.cpp com a filtragem laplaciana por cima da filtragem gaussiana
image::./Images/Exercicio_7/LoG_a.png[align="center"]
[.text-justify]
Detecta-se que o filtro gaussiano ajuda a definir e suavizar as regiões de transição encontradas pelo filtro gaussiano.

== Exercício 8

== Exercício 9
[.text-justify]
O exercício 9 tem como objetivo mostrar como as imagens são representadas no espectro da frequência através da transformada de Fourier e para isso, utilizou a imagem da senoide criada no Exercício 3 com 8 períodos. Ademais, a tarefa busca criar o programa <<dftfile>> que é capaz de ler arquivos do tipo YAML da senoide, a fim de mostrar a diferença que o tipo de armazenamento faz no espectro da frequência de uma imagem.

[[dftfile,dftyaml.cpp]]
[source,cpp]
.dftyaml.cpp
----
#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp>
#include <sstream>
#include <string>

void swapQuadrants(cv::Mat& image) {
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para o maior
  // tamanho par possivel (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols & -2, image.rows & -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que 
  // a origem fique no centro da imagem
  // A B   ->  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrants (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrant (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

int main(int argc, char** argv) {
  cv::Mat image, padded, complexImage;
  std::vector<cv::Mat> planos;
  cv::FileStorage fs;
/*
  image = imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty()) {
    std::cout << "Erro abrindo imagem" << argv[1] << std::endl;
    return EXIT_FAILURE;
  }
*/
  fs.open(argv[1], cv::FileStorage::READ);
  fs["mat"] >> image;
  //cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image,CV_8U);

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols); 
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_<float>(padded)); 
  // depois a parte imaginaria com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma unica estrutura de dados complexa
  cv::merge(planos, complexImage);  

  // calcula a DFT
  cv::dft(complexImage, complexImage); 
  swapQuadrants(complexImage);

  // planos[0] : Re(DFT(image)
  // planos[1] : Im(DFT(image)
  cv::split(complexImage, planos);

  // calcula o espectro de magnitude e de fase (em radianos)
  cv::Mat magn, fase;
  cv::cartToPolar(planos[0], planos[1], magn, fase, false);
  cv::normalize(fase, fase, 0, 1, cv::NORM_MINMAX);

  // caso deseje apenas o espectro de magnitude da DFT, use:
  cv::magnitude(planos[0], planos[1], magn); 

  // some uma constante para evitar log(0)
  // log(1 + sqrt(Re(DFT(image))^2 + Im(DFT(image))^2))
  magn += cv::Scalar::all(1);

  // calcula o logaritmo da magnitude para exibir
  // com compressao de faixa dinamica
  log(magn, magn);
  cv::normalize(magn, magn, 0, 1, cv::NORM_MINMAX);

  // exibe as imagens processadas
  cv::imshow("Imagem", image);  
  cv::imshow("Espectro de magnitude", magn);
  cv::imshow("Espectro de fase", fase);

  cv::waitKey();
  return EXIT_SUCCESS;
}
----

[#sen-original]
.Senoide de 8 períodos criada
image::./Images/Exercicio_9/senoide.png[align="center"]

[dft-png]
.DFT da senoide no formato PNG
image::./Images/Exercicio_9/especMag.png[align="center"]

[dft-yml]
.DFT da senoide no formato YAML
image::./Images/Exercicio_9/yamlMag.png[align="center"]

[dft-teorico]
.DFT teórica de uma senoide
image::./Images/Exercicio_9/senTeorico.png[align="center"]

[.text-justify]
Percebe-se que a DFT da senoide lida do arquivo YAML se aproxima melhor da DFT teórica do que a senoide no formato PNG. Isto acontece pois a imagem YAML é armazenada em ponto flutuante(float) e por isso consegue gerar valores precisos da senoide, enquanto que a imagem PNG utiliza unsigned char, o que limita a precisão do dado armazenado, distorcendo o espectro da frequência.


== Exercicío 10
[.text-justify]
Este Exercício almeja a criação do programa <<morfo>> que implementa um filtro homomórfico para corrigir a iluminação de uma imagem.

[[morfo,homomorphicfilter.cpp]]
[source,cpp]
.homomorphicfilter.cpp
----
#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp>
#include <cmath>

void swapQuadrants(cv::Mat& image) {
  cv::Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para o maior
  // tamanho par possivel (-2 = 1111...1110)
  image = image(cv::Rect(0, 0, image.cols & -2, image.rows & -2));

  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  // rearranja os quadrantes da transformada de Fourier de forma que 
  // a origem fique no centro da imagem
  // A B   ->  D C
  // C D       B A
  A = image(cv::Rect(0, 0, centerX, centerY));
  B = image(cv::Rect(centerX, 0, centerX, centerY));
  C = image(cv::Rect(0, centerY, centerX, centerY));
  D = image(cv::Rect(centerX, centerY, centerX, centerY));

  // swap quadrants (Top-Left with Bottom-Right)
  A.copyTo(tmp);
  D.copyTo(A);
  tmp.copyTo(D);

  // swap quadrant (Top-Right with Bottom-Left)
  C.copyTo(tmp);
  B.copyTo(C);
  tmp.copyTo(B);
}

int gh = 5;
int gl = 5;
int d0 = 10;
int c = 10;

void makeFilter(const cv::Mat &image, cv::Mat &filter){
  cv::Mat_<float> filter2D(image.rows, image.cols);
  int centerX = image.cols / 2;
  int centerY = image.rows / 2;

  for (int i = 0; i < image.rows; i++) {
    for (int j = 0; j < image.cols; j++) {
        filter2D.at<float>(i, j) = (gh-gl)*(1-exp(-c*((i-centerX)*(i-centerX)+(j-centerY)*(j-centerY)/(d0*d0)))) + gl;
    }
  }

  cv::Mat planes[] = {cv::Mat_<float>(filter2D), cv::Mat::zeros(filter2D.size(), CV_32F)};
  cv::merge(planes, 2, filter);
}

int main(int argc, char** argv) {
  cv::Mat image, padded, complexImage;
  std::vector<cv::Mat> planos; 

  image = imread(argv[1], cv::IMREAD_GRAYSCALE);
  if (image.empty()) {
    std::cout << "Erro abrindo imagem" << argv[1] << std::endl;
    return EXIT_FAILURE;
  }
  

  // expande a imagem de entrada para o melhor tamanho no qual a DFT pode ser
  // executada, preenchendo com zeros a lateral inferior direita.
  int dft_M = cv::getOptimalDFTSize(image.rows);
  int dft_N = cv::getOptimalDFTSize(image.cols); 
  cv::copyMakeBorder(image, padded, 0, dft_M - image.rows, 0, dft_N - image.cols, cv::BORDER_CONSTANT, cv::Scalar::all(0));

  // prepara a matriz complexa para ser preenchida
  // primeiro a parte real, contendo a imagem de entrada
  planos.push_back(cv::Mat_<float>(padded)); 
  // depois a parte imaginaria com valores nulos
  planos.push_back(cv::Mat::zeros(padded.size(), CV_32F));

  // combina os planos em uma unica estrutura de dados complexa
  cv::merge(planos, complexImage);
  

  // calcula a DFT
  cv::dft(complexImage, complexImage); 
  swapQuadrants(complexImage);


  // cria o filtro ideal e aplica a filtragem de frequencia
  cv::Mat filter;
  makeFilter(complexImage, filter);
  cv::mulSpectrums(complexImage, filter, complexImage, 0);

  // calcula a DFT inversa
  swapQuadrants(complexImage);
  cv::idft(complexImage, complexImage);

  // planos[0] : Re(DFT(image)
  // planos[1] : Im(DFT(image)
  cv::split(complexImage, planos);


  // recorta a imagem filtrada para o tamanho original
  // selecionando a regiao de interesse (roi)
  cv::Rect roi(0, 0, image.cols, image.rows);
  cv::Mat result = planos[0](roi);


  // normaliza a parte real para exibicao
  cv::normalize(result, result, 0, 1, cv::NORM_MINMAX);

  cv::imshow("image", result);
  cv::imwrite("dft-filter.png", result * 255);

  cv::waitKey();
  return EXIT_SUCCESS;
}
----

[#filt-orig]
.Imagem Original
image::./Images/Exercicio_10/biel.png[align="center"]

[#filteredhomomorphic]
.Saída do programa homomorphicfilter.cpp
image::./Images/Exercicio_10/dft-filter.png[align="center"]

[.text-justify]
É possível notar que o filtro foi capaz de realçar a iluminação da imagem, tornando-a mais nítida.


== Exercício 11
[.text-justify]
O exercício 11 trata de implementar a técnica do pointilhismo digital com o algoritmo de canny para melhorar a qualidade imagem pontilhada.

[source,cpp]
.cannypoints.cpp
----
#include <algorithm>
#include <cstdlib>
#include <ctime>
#include <fstream>
#include <iomanip>
#include <iostream>
#include <numeric>
#include <opencv2/opencv.hpp>
#include <vector>


#define STEP 5
#define JITTER 3
#define RAIO 5

int top_slider = 10;
int top_slider_max = 200;

char TrackbarName[50];

cv::Mat image, border, points, imageGray;
cv::Vec3b color;

int width, height;
int x, y;

std::vector<int> yrange;
std::vector<int> xrange;

void on_trackbar_canny(int, void*){
  cv::Canny(imageGray, border, top_slider, 3*top_slider);
  cv::imshow("Cannyborder", border);

  points = cv::Mat(height, width, CV_8UC3, cv::Scalar(255,255,255));

  std::random_shuffle(xrange.begin(), xrange.end());

  for (auto i : xrange) {
    std::random_shuffle(yrange.begin(), yrange.end());
    for (auto j : yrange) {
        if(border.at<uchar>(i,j) == 255){
            x = i + std::rand() % (2 * JITTER) - JITTER + 1;
            y = j + std::rand() % (2 * JITTER) - JITTER + 1;
            color = image.at<cv::Vec3b>(x, y);
            cv::circle(points, cv::Point(y, x), 2, CV_RGB(color[2], color[1], color[0]),
                        cv::FILLED, cv::LINE_AA);
        }
        else{
            x = i + std::rand() % (2 * JITTER) - JITTER + 1;
            y = j + std::rand() % (2 * JITTER) - JITTER + 1;
            color = image.at<cv::Vec3b>(x, y);
            cv::circle(points, cv::Point(y, x), RAIO, CV_RGB(color[2], color[1], color[0]),
                        cv::FILLED, cv::LINE_AA);
        }
    }
  }
}

int main(int argc, char**argv){
  image = cv::imread(argv[1], cv::IMREAD_COLOR);
  cv::cvtColor(image, imageGray,cv::COLOR_BGR2GRAY);

  std::srand(std::time(0));

  if (image.empty()) {
    std::cout << "Could not open or find the image" << std::endl;
    return -1;
  }

  width = image.cols;
  height = image.rows;

  xrange.resize(height / STEP);
  yrange.resize(width / STEP);

  std::iota(xrange.begin(), xrange.end(), 0);
  std::iota(yrange.begin(), yrange.end(), 0);

  for (uint i = 0; i < xrange.size(); i++) {
    xrange[i] = xrange[i] * STEP + STEP / 2;
  }

  for (uint i = 0; i < yrange.size(); i++) {
    yrange[i] = yrange[i] * STEP + STEP / 2;
  }
  
  sprintf( TrackbarName, "Threshold inferior", top_slider_max );

  cv::namedWindow("Canny",1);
  cv::createTrackbar( TrackbarName, "Canny",
                &top_slider,
                top_slider_max,
                on_trackbar_canny );

  on_trackbar_canny(top_slider, 0 );

  cv::waitKey();
  cv::imwrite("cannypoints.png", points);

  return 0;
}
----
[.text-justify]
Este programa incorpora funções dos dois programas fornecidos na questão, sendo estes o canny.ccp e o pointilhismo.cpp, executando as funções de:
[.text-justify]
* Inicialmente a imagem será dividida em duas, uma imagem colorida e uma imagem em tons de cinza;
* A imagem em tons de cinza será usada no algoritmo de canny para obter a imagem binária que representa as bordas, com o número de bordas sendo definido pelo usuário com uma barra deslizante que indica o threshold inferior;
* Após isso serão escolhidas posições aleatórias na imagem, nas quais serão desenhadas círculos em uma terceira matriz de imagem de raio de 5 pixels com o tom de cor do centro da imagem colorida original para os locais que a matriz derivada do algoritmo de canny não detectar bordas;
* Já nos locais na matriz de canny que possuem bordas, equivalerão à círculos de raio de 2 pixels na matriz de desenho de tal maneira a criar um desenho mais detalhado nas bordas detectadas.

[#paisagem]
.Imagem Original
image::./Images/Exercicio_11/paisagem.jpeg[align="center"]

[#pontilhada]
.Saída do programa cannypoints.cpp
image::./Images/Exercicio_11/cannypoints.png[align="center"]








== Projeto

[.text-justify]
O projeto escolhido foi de criar um efeito de traçado de luz de forma digital, pois a maneira habitual de se criar este efeito se dá através da mudar das configurações da câmera, a fim de manter o obturador totalmente aberto durante a tomada da foto. Todavia, para alguém que não possua uma câmera que permita a mudança destas configurações, o programa <<trace>> buscar recriar o mesmo efeito.

[#ex]
.Imagem de exemplo do efeito a ser recriado
image::./Images/projeto/LightTrails-featured.jpg[align="center"]

[[trace, traces.cpp]]
[source, cpp]
.traces.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv){
    cv::Mat image, lixo, acumulador, media;
    cv::VideoCapture cap(argv[1]);
    int width, height;


    if(!cap.isOpened()){
        std::cout << "Error to load video" << std::endl;
        return -1;
    }

    width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
    height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

    int fourcc = cv::VideoWriter::fourcc('P', 'I', 'M', '1');
    cv::Size framesize(static_cast<int>(width), static_cast<int>(height));
    cv::VideoWriter video("traces.avi",fourcc, 20, framesize, true);

    acumulador = cv::Mat::zeros(height,width, CV_8UC3);

    while(cap.isOpened()){
        cap >> image;
        for(int i = 0; i < height; i++){
            for(int j = 0; j < 3*width; j++){
                acumulador.at<uchar>(i,j) = std::max(acumulador.at<uchar>(i,j), image.at<uchar>(i,j));
            }
        }

        video.write(acumulador);
        if(cap.get(cv::CAP_PROP_POS_FRAMES) == cap.get(cv::CAP_PROP_FRAME_COUNT)) break;
    }

    cap.release();
    video.release();
    
    return 0;
}
----
[.text-justify]
O código segue os seguintes passos:
[.text-justify]
* Abre o arquivo de vídeo, checa suas dimensões e retorna caso o arquivo não tenha sido aberto corretamente;
* Começa a capturar os quadros e a cada quadro compara com o quadro anterior, buscando quais píxels tem maior tom de brílho utilizando a função <<std::max()>>;
* Após identificar todos os valores máximos de brilho de cada píxel dos quadros comparados, o quadro resultante é gravado no arquivo de saída em formato .avi;
* A condição de parada da captura de quadros é quando o frame atual se iguala ao último frame do arquivo.

Para o vídeo:
[#Original]
.Video original
image::./Images/projeto/final.png[aling="center"]

[.text-justify]
Este é o resultado:
[#traces]
.Saída do programa traces.cpp
image::./Images/projeto/traces.png[align="center"]